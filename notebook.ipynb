{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czETk5YtDVOW",
        "outputId": "8423d7d0-c674-4afb-f71e-d7ace7d0857f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.18.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.18)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.61.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Collecting PyMuPDF\n",
            "  Downloading pymupdf-1.25.3-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.34 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.35)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.38)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.12)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain) (24.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.27.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain) (3.0.0)\n",
            "Downloading groq-0.18.0-py3-none-any.whl (121 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m121.9/121.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pymupdf-1.25.3-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDF, groq\n",
            "Successfully installed PyMuPDF-1.25.3 groq-0.18.0\n"
          ]
        }
      ],
      "source": [
        "!pip install groq langchain openai streamlit gradio pandas nltk PyMuPDF langchain-community reportlab"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"GROQ_API_KEY\"] = \"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\""
      ],
      "metadata": {
        "id": "TZ759HOkEWfj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import fitz\n",
        "import nltk\n",
        "import pandas as pd\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import HumanMessage\n",
        "\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    openai_api_key=groq_api_key,\n",
        "    model_name=\"mixtral-8x7b-32768\",\n",
        "    temperature=0.7,\n",
        "    base_url=\"https://api.groq.com/openai/v1\"\n",
        ")\n",
        "\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    \"\"\"\n",
        "    Extracts text from a given PDF file.\n",
        "    \"\"\"\n",
        "    doc = fitz.open(pdf_path)\n",
        "    text = \"\"\n",
        "    for page in doc:\n",
        "        text += page.get_text(\"text\") + \"\\n\"\n",
        "    return text.strip()\n",
        "\n",
        "def analyze_resume(resume_text, job_description):\n",
        "    \"\"\"\n",
        "    Sends the resume text and job description to the LLM and retrieves an analysis.\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    Given the following resume:\n",
        "    {resume_text}\n",
        "\n",
        "    And the following job description:\n",
        "    {job_description}\n",
        "\n",
        "    Extract the following:\n",
        "    - Candidate's Name\n",
        "    - Key Skills\n",
        "    - Years of Experience\n",
        "    - Education\n",
        "    - A suitability score (1-10) based on job requirements.\n",
        "\n",
        "    Format the response in a structured JSON format.\n",
        "    \"\"\"\n",
        "\n",
        "    response = llm([HumanMessage(content=prompt)])\n",
        "    return response.content\n",
        "\n",
        "def process_resumes(resume_folder, job_description):\n",
        "    \"\"\"\n",
        "    Loops through all resumes in a folder, extracts text, and runs analysis.\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    for file_name in os.listdir(resume_folder):\n",
        "        if file_name.endswith(\".pdf\"):\n",
        "            resume_path = os.path.join(resume_folder, file_name)\n",
        "            resume_text = extract_text_from_pdf(resume_path)\n",
        "            analysis = analyze_resume(resume_text, job_description)\n",
        "            results.append({\"Candidate\": file_name, \"Analysis\": analysis})\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "job_description = \"We are looking for a software engineer with Python, NLP, and machine learning experience.\"\n",
        "\n",
        "resume_folder = \"./resumes\"\n",
        "results_df = process_resumes(resume_folder, job_description)\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLjbSDX5FEGJ",
        "outputId": "7d322229-b955-4cd8-f53b-41315a509e55"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Candidate                                           Analysis\n",
            "0  data_resume.pdf  {\\n  \"candidate_name\": \"Nayab Irfan\",\\n  \"key_...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to get results in an excel sheet\n",
        "import pandas as pd\n",
        "print(\"Resume Screening Results\")\n",
        "print(results_df)\n",
        "from IPython.display import display\n",
        "display(results_df)\n",
        "\n",
        "results_df.to_csv('resume_screening_results.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "gIeyZHvOMuBY",
        "outputId": "6789664d-434f-49fe-acde-51d8d3691777"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resume Screening Results\n",
            "         Candidate                                           Analysis\n",
            "0  data_resume.pdf  {\\n  \"candidate_name\": \"Nayab Irfan\",\\n  \"key_...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "         Candidate                                           Analysis\n",
              "0  data_resume.pdf  {\\n  \"candidate_name\": \"Nayab Irfan\",\\n  \"key_..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a36c2706-ff0b-46ef-95a1-fefeebd32704\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Candidate</th>\n",
              "      <th>Analysis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>data_resume.pdf</td>\n",
              "      <td>{\\n  \"candidate_name\": \"Nayab Irfan\",\\n  \"key_...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a36c2706-ff0b-46ef-95a1-fefeebd32704')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a36c2706-ff0b-46ef-95a1-fefeebd32704 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a36c2706-ff0b-46ef-95a1-fefeebd32704');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_fcdf05b1-c29a-46fd-8184-f4e385ca8ee5\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_fcdf05b1-c29a-46fd-8184-f4e385ca8ee5 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results_df",
              "summary": "{\n  \"name\": \"results_df\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Candidate\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"data_resume.pdf\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Analysis\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"{\\n  \\\"candidate_name\\\": \\\"Nayab Irfan\\\",\\n  \\\"key_skills\\\": [\\n    \\\"Python\\\",\\n    \\\"NLP\\\",\\n    \\\"Machine Learning\\\",\\n    \\\"Data Science\\\",\\n    \\\"AI\\\",\\n    \\\"Cybersecurity\\\",\\n    \\\"Programming\\\",\\n    \\\"HTML\\\",\\n    \\\"CSS\\\",\\n    \\\"SQL\\\",\\n    \\\"Jupyter\\\",\\n    \\\"Numpy\\\",\\n    \\\"Pandas\\\",\\n    \\\"Matplotlib\\\",\\n    \\\"Scikit Learn\\\",\\n    \\\"TensorFlow\\\",\\n    \\\"Pytorch\\\",\\n    \\\"Gradio\\\",\\n    \\\"CV\\\",\\n    \\\"Stable Diffusion\\\",\\n    \\\"YOLO\\\",\\n    \\\"Hugging Face\\\",\\n    \\\"SQL Joins\\\",\\n    \\\"CTEs\\\",\\n    \\\"Advanced Microsoft Excel\\\",\\n    \\\"Power BI\\\",\\n    \\\"CUDA\\\",\\n    \\\"APIs\\\",\\n    \\\"RDBMS\\\",\\n    \\\"Graphic Designing\\\",\\n    \\\"Kali Linux\\\",\\n    \\\"Metasploit\\\",\\n    \\\"Bash Scripting\\\",\\n    \\\"RAT (remote access trojans)\\\",\\n    \\\"SETOOLKIT\\\",\\n    \\\"Machine Learning\\\",\\n    \\\"Deep Learning\\\",\\n    \\\"Artificial Intelligence\\\",\\n    \\\"Generative AI\\\",\\n    \\\"Databases\\\"\\n  ],\\n  \\\"years_of_experience\\\": 1,\\n  \\\"education\\\": [\\n    {\\n      \\\"institution\\\": \\\"University of Central Punjab\\\",\\n      \\\"degree\\\": \\\"Bachelors in Computer Science\\\",\\n      \\\"start_year\\\": 2022,\\n      \\\"end_year\\\": 2026,\\n      \\\"cgpa\\\": 3.24\\n    },\\n    {\\n      \\\"institution\\\": \\\"Atomcamp\\\",\\n      \\\"degree\\\": \\\"Data Science and AI bootcamp\\\",\\n      \\\"start_year\\\": 2024,\\n      \\\"end_year\\\": 2025\\n    },\\n    {\\n      \\\"institution\\\": \\\"University of Engineering and Technology\\\",\\n      \\\"degree\\\": \\\"Machine Learning in Artificial intelligence\\\",\\n      \\\"start_year\\\": 2022,\\n      \\\"end_year\\\": 2022,\\n      \\\"final_grade\\\": \\\"A\\\"\\n    },\\n    {\\n      \\\"institution\\\": \\\"Lahore College For Women University\\\",\\n      \\\"degree\\\": \\\"FSC-Pre Engineering\\\",\\n      \\\"start_year\\\": 2019,\\n      \\\"end_year\\\": 2021,\\n      \\\"final_grade\\\": \\\"A\\\"\\n    }\\n  ],\\n  \\\"suitability_score\\\": 8\\n}\\n\\nComments:\\n- The candidate has strong experience in Python, NLP, and machine learning.\\n- She has 1 year of experience in relevant roles.\\n- The candidate is currently pursuing a Bachelors in Computer Science and a Data Science and AI bootcamp.\\n- The suitability score is 8, as the candidate has strong technical skills but lacks experience in some of the required tools and frameworks.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import fitz\n",
        "import nltk\n",
        "import pandas as pd\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import HumanMessage\n",
        "from reportlab.lib.pagesizes import letter\n",
        "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n",
        "from reportlab.lib.styles import getSampleStyleSheet\n",
        "\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "# Set API key for Groq\n",
        "os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
        "\n",
        "# Initialize the LLM model with Groq API\n",
        "llm = ChatOpenAI(\n",
        "    openai_api_key=os.getenv(\"GROQ_API_KEY\"),\n",
        "    model_name=\"mixtral-8x7b-32768\",\n",
        "    temperature=0.7,\n",
        "    base_url=\"https://api.groq.com/openai/v1\"\n",
        ")\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    \"\"\"Extracts text from a given PDF file.\"\"\"\n",
        "    doc = fitz.open(pdf_path)\n",
        "    text = \"\\n\".join(page.get_text(\"text\") for page in doc)\n",
        "    return text.strip()\n",
        "\n",
        "def extract_candidate_name(resume_text):\n",
        "    \"\"\"Attempts to extract the candidate's name using regex (assuming common resume formats).\"\"\"\n",
        "    name_patterns = [\n",
        "        r\"Name:\\s*([A-Za-z\\s]+)\",\n",
        "        r\"([A-Z][a-z]+ [A-Z][a-z]+)\",\n",
        "        r\"([A-Z][a-z]+\\s[A-Z]\\.\\s[A-Z][a-z]+)\",\n",
        "    ]\n",
        "\n",
        "    for pattern in name_patterns:\n",
        "        match = re.search(pattern, resume_text)\n",
        "        if match:\n",
        "            return match.group(1).strip()\n",
        "\n",
        "    return \"Unknown Candidate\"\n",
        "\n",
        "    title_style = ParagraphStyle(\n",
        "        'TitleStyle', parent=styles['Title'], fontSize=18, textColor=colors.darkblue, spaceAfter=10\n",
        "    )\n",
        "    heading_style = ParagraphStyle(\n",
        "        'HeadingStyle', parent=styles['Heading2'], fontSize=14, textColor=colors.black, spaceAfter=6, bold=True\n",
        "    )\n",
        "    normal_style = ParagraphStyle(\n",
        "        'NormalStyle', parent=styles['Normal'], fontSize=12, textColor=colors.darkgray\n",
        "    )\n",
        "\n",
        "def analyze_resume(resume_text):\n",
        "    \"\"\"Analyzes the resume and provides structured insights using LLM.\"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    Analyze the following resume and extract structured details:\n",
        "\n",
        "    {resume_text}\n",
        "\n",
        "    Output format (JSON):\n",
        "    {{\n",
        "      \"Candidate_Name\": \"<Extracted Name>\",\n",
        "      \"Key_Skills\": [\"Skill1\", \"Skill2\", \"Skill3\"],\n",
        "      \"Years_of_Experience\": <Number>,\n",
        "      \"Education\": [\"Degree1\", \"Degree2\"],\n",
        "      \"Suitable_Roles\": [\"Role1\", \"Role2\", \"Role3\"],\n",
        "      \"Suitability_Score\": <Score out of 10>,\n",
        "      \"Career_Advice\": \"<Detailed career advice based on skills and experience>\"\n",
        "    }}\n",
        "    \"\"\"\n",
        "\n",
        "    response = llm([HumanMessage(content=prompt)]).content\n",
        "\n",
        "    try:\n",
        "        structured_data = eval(response)\n",
        "    except:\n",
        "        print(\"Error parsing LLM response. Check output format.\")\n",
        "        structured_data = {\n",
        "            \"Candidate_Name\": extract_candidate_name(resume_text),\n",
        "            \"Key_Skills\": [],\n",
        "            \"Years_of_Experience\": \"N/A\",\n",
        "            \"Education\": [],\n",
        "            \"Suitable_Roles\": [],\n",
        "            \"Suitability_Score\": \"N/A\",\n",
        "            \"Career_Advice\": \"Analysis could not be completed.\"\n",
        "        }\n",
        "\n",
        "    return structured_data\n",
        "\n",
        "def generate_pdf_report(resume_folder):\n",
        "    \"\"\"Generates a detailed AI-powered resume screening report in PDF format.\"\"\"\n",
        "    doc = SimpleDocTemplate(\"analysis_report.pdf\", pagesize=letter)\n",
        "    styles = getSampleStyleSheet()\n",
        "    story = []\n",
        "\n",
        "    for file_name in os.listdir(resume_folder):\n",
        "        if file_name.endswith(\".pdf\"):\n",
        "            resume_path = os.path.join(resume_folder, file_name)\n",
        "            resume_text = extract_text_from_pdf(resume_path)\n",
        "            analysis = analyze_resume(resume_text)\n",
        "\n",
        "            name = analysis.get(\"Candidate_Name\", \"Unknown Candidate\")\n",
        "            skills = \", \".join(analysis.get(\"Key_Skills\", []))\n",
        "            experience = analysis.get(\"Years_of_Experience\", \"N/A\")\n",
        "            education = \", \".join(analysis.get(\"Education\", []))\n",
        "            roles = \", \".join(analysis.get(\"Suitable_Roles\", []))\n",
        "            score = analysis.get(\"Suitability_Score\", \"N/A\")\n",
        "            advice = analysis.get(\"Career_Advice\", \"No advice available.\")\n",
        "\n",
        "            story.append(Paragraph(f\"Resume Analysis for {name}\", styles['Title']))\n",
        "            story.append(Spacer(1, 12))\n",
        "            story.append(Paragraph(f\"Candidate Name: {name}\", styles['Normal']))\n",
        "            story.append(Paragraph(f\"Key Skills: {skills}\", styles['Normal']))\n",
        "            story.append(Paragraph(f\"Years of Experience: {experience}\", styles['Normal']))\n",
        "            story.append(Paragraph(f\"Education: {education}\", styles['Normal']))\n",
        "            story.append(Paragraph(f\"Suitable Roles: {roles}\", styles['Normal']))\n",
        "            story.append(Paragraph(f\"Suitability Score: {score}/10\", styles['Normal']))\n",
        "            story.append(Spacer(1, 12))\n",
        "            story.append(Paragraph(f\"Personalized Career Advice:\", styles['h2']))\n",
        "            story.append(Paragraph(advice, styles['Normal']))\n",
        "            story.append(Spacer(1, 24))  # Extra space before next resume\n",
        "\n",
        "    doc.build(story)\n",
        "    print(\"AI-Powered Resume Screening Report saved as analysis_report.pdf\")\n",
        "\n",
        "resume_folder = \"./resumes\"\n",
        "generate_pdf_report(resume_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uaCEjehQ7Vi",
        "outputId": "c92d5ee9-42d2-4443-f27a-4d6a9ed5dd61"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI-Powered Resume Screening Report saved as analysis_report.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import fitz\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import streamlit as st\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import HumanMessage\n",
        "from reportlab.lib.pagesizes import letter\n",
        "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n",
        "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
        "from reportlab.lib import colors\n",
        "\n",
        "# Download NLTK tokenizer\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "# Set API key for Groq\n",
        "os.environ[\"GROQ_API_KEY\"] = \"your_groq_api_key_here\"\n",
        "\n",
        "# Initialize LLM\n",
        "llm = ChatOpenAI(\n",
        "    openai_api_key=os.getenv(\"GROQ_API_KEY\"),\n",
        "    model_name=\"mixtral-8x7b-32768\",\n",
        "    temperature=0.7,\n",
        "    base_url=\"https://api.groq.com/openai/v1\"\n",
        ")\n",
        "\n",
        "# Streamlit UI\n",
        "st.set_page_config(page_title=\"AI Resume Analyzer\", layout=\"centered\")\n",
        "st.title(\"AI Resume Analyzer\")\n",
        "\n",
        "# Upload PDF File\n",
        "uploaded_file = st.file_uploader(\"Upload a Resume (PDF)\", type=[\"pdf\"])\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    \"\"\"Extract text from a given PDF file.\"\"\"\n",
        "    doc = fitz.open(pdf_path)\n",
        "    text = \"\\n\".join(page.get_text(\"text\") for page in doc)\n",
        "    return text.strip()\n",
        "\n",
        "def analyze_resume(resume_text):\n",
        "    \"\"\"Analyze resume content using LLM.\"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    Analyze the following resume and extract structured details:\n",
        "\n",
        "    {resume_text}\n",
        "\n",
        "    Output format (JSON):\n",
        "    {{\n",
        "      \"Candidate_Name\": \"<Extracted Name>\",\n",
        "      \"Key_Skills\": [\"Skill1\", \"Skill2\", \"Skill3\"],\n",
        "      \"Years_of_Experience\": <Number>,\n",
        "      \"Education\": [\"Degree1\", \"Degree2\"],\n",
        "      \"Suitable_Roles\": [\"Role1\", \"Role2\", \"Role3\"],\n",
        "      \"Suitability_Score\": <Score out of 10>,\n",
        "      \"Career_Advice\": \"<Detailed career advice based on skills and experience>\"\n",
        "    }}\n",
        "    \"\"\"\n",
        "\n",
        "    response = llm([HumanMessage(content=prompt)]).content\n",
        "    try:\n",
        "        structured_data = eval(response)\n",
        "    except:\n",
        "        structured_data = {\n",
        "            \"Candidate_Name\": \"Unknown\",\n",
        "            \"Key_Skills\": [],\n",
        "            \"Years_of_Experience\": \"N/A\",\n",
        "            \"Education\": [],\n",
        "            \"Suitable_Roles\": [],\n",
        "            \"Suitability_Score\": \"N/A\",\n",
        "            \"Career_Advice\": \"Analysis failed.\"\n",
        "        }\n",
        "    return structured_data\n",
        "\n",
        "def generate_pdf_report(analysis):\n",
        "    \"\"\"Generate a detailed resume analysis report in PDF.\"\"\"\n",
        "    pdf_path = \"resume_analysis_report.pdf\"\n",
        "    doc = SimpleDocTemplate(pdf_path, pagesize=letter)\n",
        "    styles = getSampleStyleSheet()\n",
        "\n",
        "    title_style = ParagraphStyle('TitleStyle', parent=styles['Title'], fontSize=18, textColor=colors.darkblue)\n",
        "    heading_style = ParagraphStyle('HeadingStyle', parent=styles['Heading2'], fontSize=14, textColor=colors.black, bold=True)\n",
        "    normal_style = ParagraphStyle('NormalStyle', parent=styles['Normal'], fontSize=12, textColor=colors.darkgray)\n",
        "\n",
        "    story = []\n",
        "    name = analysis.get(\"Candidate_Name\", \"Unknown Candidate\")\n",
        "    skills = \", \".join(analysis.get(\"Key_Skills\", []))\n",
        "    experience = analysis.get(\"Years_of_Experience\", \"N/A\")\n",
        "    education = \", \".join(analysis.get(\"Education\", []))\n",
        "    roles = \", \".join(analysis.get(\"Suitable_Roles\", []))\n",
        "    score = analysis.get(\"Suitability_Score\", \"N/A\")\n",
        "    advice = analysis.get(\"Career_Advice\", \"No advice available.\")\n",
        "\n",
        "    story.append(Paragraph(f\"Resume Analysis Report\", title_style))\n",
        "    story.append(Spacer(1, 12))\n",
        "    story.append(Paragraph(f\"Candidate Name: {name}\", heading_style))\n",
        "    story.append(Paragraph(f\"Key Skills: {skills}\", normal_style))\n",
        "    story.append(Paragraph(f\"Years of Experience: {experience}\", normal_style))\n",
        "    story.append(Paragraph(f\"Education: {education}\", normal_style))\n",
        "    story.append(Paragraph(f\"Suitable Roles: {roles}\", normal_style))\n",
        "    story.append(Paragraph(f\"Suitability Score: {score}/10\", normal_style))\n",
        "    story.append(Spacer(1, 12))\n",
        "    story.append(Paragraph(f\"Career Advice:\", heading_style))\n",
        "    story.append(Paragraph(advice, normal_style))\n",
        "    story.append(Spacer(1, 24))\n",
        "\n",
        "    doc.build(story)\n",
        "    return pdf_path\n",
        "\n",
        "if uploaded_file:\n",
        "    with open(\"uploaded_resume.pdf\", \"wb\") as f:\n",
        "        f.write(uploaded_file.getbuffer())\n",
        "\n",
        "    st.success(\"Resume Uploaded Successfully!\")\n",
        "\n",
        "    resume_text = extract_text_from_pdf(\"uploaded_resume.pdf\")\n",
        "\n",
        "    # Analyze Resume\n",
        "    with st.spinner(\"Analyzing Resume...\"):\n",
        "        analysis = analyze_resume(resume_text)\n",
        "\n",
        "    # Show Results\n",
        "    st.subheader(\"Resume Analysis Result\")\n",
        "    st.write(f\"**Candidate Name:** {analysis['Candidate_Name']}\")\n",
        "    st.write(f\"**Key Skills:** {', '.join(analysis['Key_Skills'])}\")\n",
        "    st.write(f\"**Years of Experience:** {analysis['Years_of_Experience']}\")\n",
        "    st.write(f\"**Education:** {', '.join(analysis['Education'])}\")\n",
        "    st.write(f\"**Suitable Roles:** {', '.join(analysis['Suitable_Roles'])}\")\n",
        "    st.write(f\"**Suitability Score:** {analysis['Suitability_Score']}/10\")\n",
        "    st.write(f\"**Career Advice:** {analysis['Career_Advice']}\")\n",
        "\n",
        "    # Generate PDF Report\n",
        "    with st.spinner(\"üìÑ Generating PDF Report...\"):\n",
        "        pdf_path = generate_pdf_report(analysis)\n",
        "\n",
        "    # Provide Download Button\n",
        "    with open(pdf_path, \"rb\") as pdf_file:\n",
        "        st.download_button(\n",
        "            label=\"Download Report\",\n",
        "            data=pdf_file,\n",
        "            file_name=\"Resume_Analysis_Report.pdf\",\n",
        "            mime=\"application/pdf\"\n",
        "        )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z05ZTURlV-Ju",
        "outputId": "463624b4-89ce-4466-8d43-bbb6016056c0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "2025-02-15 16:02:06.903 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-15 16:02:06.905 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-15 16:02:06.968 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2025-02-15 16:02:06.969 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-15 16:02:06.972 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-15 16:02:06.974 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-15 16:02:06.975 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-15 16:02:06.977 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-15 16:02:06.979 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run /usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9skMvBhcWP9_",
        "outputId": "395eaa4c-bc3d-47bb-f284-c98bec1acfd2"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.247.121.113:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import fitz\n",
        "import gradio as gr\n",
        "import json\n",
        "import nltk\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import HumanMessage\n",
        "from reportlab.lib.pagesizes import letter\n",
        "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n",
        "from reportlab.lib.styles import getSampleStyleSheet\n",
        "\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "# ‚úÖ Faster Model + Lower Temperature\n",
        "llm = ChatOpenAI(\n",
        "    openai_api_key=os.getenv(\"GROQ_API_KEY\"),\n",
        "    model_name=\"gpt-3.5-turbo\",  # Faster than Mixtral-8x7b\n",
        "    temperature=0.7,\n",
        ")\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    \"\"\"Extracts key sections from the resume.\"\"\"\n",
        "    doc = fitz.open(pdf_path)\n",
        "    all_text = \"\\n\".join(page.get_text(\"text\") for page in doc)\n",
        "\n",
        "    sections = all_text.split(\"\\n\")\n",
        "    keywords = [\"Experience\", \"Skills\", \"Education\", \"Summary\", \"Projects\"]\n",
        "    filtered_text = \"\\n\".join([s for s in sections if any(k in s for k in keywords)])\n",
        "\n",
        "    return filtered_text if filtered_text else all_text[:1000]\n",
        "\n",
        "def analyze_resume(resume_text):\n",
        "    \"\"\"Uses LLM to analyze and extract structured details.\"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    Summarize the resume below and extract key details in JSON:\n",
        "\n",
        "    {resume_text[:1500]}\n",
        "\n",
        "    JSON Format:\n",
        "    {{\n",
        "      \"Candidate_Name\": \"<Extracted Name>\",\n",
        "      \"Key_Skills\": [\"Skill1\", \"Skill2\"],\n",
        "      \"Years_of_Experience\": <Number>,\n",
        "      \"Education\": [\"Degree1\", \"Degree2\"],\n",
        "      \"Suitable_Roles\": [\"Role1\", \"Role2\"],\n",
        "      \"Suitability_Score\": <Score out of 10>,\n",
        "      \"Career_Advice\": \"<Short Career Advice>\"\n",
        "    }}\n",
        "    \"\"\"\n",
        "\n",
        "    response = llm([HumanMessage(content=prompt)]).content\n",
        "    try:\n",
        "        return json.loads(response)\n",
        "    except json.JSONDecodeError:\n",
        "        return {\"error\": \"AI response parsing failed. Try again!\"}\n",
        "\n",
        "def generate_pdf_report(resume_text):\n",
        "    \"\"\"Creates a well-structured PDF with AI insights.\"\"\"\n",
        "    analysis = analyze_resume(resume_text)\n",
        "    if \"error\" in analysis:\n",
        "        return analysis[\"error\"]\n",
        "\n",
        "    pdf_filename = \"resume_analysis.pdf\"\n",
        "    doc = SimpleDocTemplate(pdf_filename, pagesize=letter)\n",
        "    styles = getSampleStyleSheet()\n",
        "    story = []\n",
        "\n",
        "    story.append(Paragraph(\"Resume Analysis Report\", styles['Title']))\n",
        "    story.append(Spacer(1, 12))\n",
        "\n",
        "    for key, value in analysis.items():\n",
        "        if isinstance(value, list):\n",
        "            value = \", \".join(value)\n",
        "        story.append(Paragraph(f\"<b>{key.replace('_', ' ')}:</b> {value}\", styles['Normal']))\n",
        "        story.append(Spacer(1, 10))\n",
        "\n",
        "    doc.build(story)\n",
        "    return pdf_filename\n",
        "\n",
        "def process_resume(pdf_file):\n",
        "    \"\"\"Handles file upload, extracts text, and generates the analysis report.\"\"\"\n",
        "    resume_text = extract_text_from_pdf(pdf_file.name)\n",
        "    pdf_filename = generate_pdf_report(resume_text)\n",
        "    return f\"Analysis complete! Download your report:\", pdf_filename\n",
        "\n",
        "# Optimize Gradio Launch\n",
        "iface = gr.Interface(\n",
        "    fn=process_resume,\n",
        "    inputs=gr.File(label=\"Upload Resume (PDF)\"),\n",
        "    outputs=[gr.Text(), gr.File(label=\"Download Report\")],\n",
        "    title=\"‚ö° AI-Powered Resume Analyzer\",\n",
        "    description=\"Upload a resume and get a structured AI-generated analysis instantly!\"\n",
        ")\n",
        "\n",
        "iface.launch(share=True)  # Faster execution\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "U-3dal7MY-4M",
        "outputId": "e9cc7fdc-76e3-490d-acb1-1fae854f5ac6"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://5711a666116f66ca36.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://5711a666116f66ca36.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    }
  ]
}